{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         asin                                           document  label\n",
      "0  B079SPVPKD  the sea broke out in prayer and began to recit...      1\n",
      "1  1982617519  hadn't expected to say this i couldn't possibl...      1\n",
      "2  B003SAZ1GW  plan and take it in doses and you'll get hooke...      0\n",
      "3  B01N4KZCKO  the flying father they called him and boy was ...      1\n",
      "4  B005SUYVYI  advanced learning courses for business success...      0\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.read_csv('../data/corpus/Biographies_&_Memoirs.csv')\n",
    "print(corpus_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Sum Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract documents and labels from the DataFrame\n",
    "corpus = corpus_df['document']\n",
    "labels = corpus_df['label']\n",
    "\n",
    "# Calculate TF-IDF \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.5, min_df=10, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "terms_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create DataFrame for TF-IDF scores with labels\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=terms_tfidf)\n",
    "tfidf_df['Genre'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067562</td>\n",
       "      <td>0.156546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.102868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  absolutely  according   account  act    action  actually  \\\n",
       "0    0.000000   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "1    0.000000   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "2    0.077104   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "3    0.000000   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "4    0.000000   0.0    0.054144        0.0  0.056633  0.0  0.108288       0.0   \n",
       "..        ...   ...         ...        ...       ...  ...       ...       ...   \n",
       "175  0.000000   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "176  0.000000   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "177  0.000000   0.0    0.000000        0.0  0.000000  0.0  0.000000       0.0   \n",
       "178  0.102868   0.0    0.000000        0.0  0.102868  0.0  0.000000       0.0   \n",
       "179  0.000000   0.0    0.000000        0.0  0.000000  0.0  0.038574       0.0   \n",
       "\n",
       "     add  added  ...  written     wrong  wrote      yeah      year    yellow  \\\n",
       "0    0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.000000  0.071436   \n",
       "1    0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "2    0.0    0.0  ...      0.0  0.066016    0.0  0.000000  0.000000  0.000000   \n",
       "3    0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "4    0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "..   ...    ...  ...      ...       ...    ...       ...       ...       ...   \n",
       "175  0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.055880  0.000000   \n",
       "176  0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "177  0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.045669  0.000000   \n",
       "178  0.0    0.0  ...      0.0  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "179  0.0    0.0  ...      0.0  0.034545    0.0  0.035726  0.000000  0.000000   \n",
       "\n",
       "          yes      york     young  Genre  \n",
       "0    0.000000  0.000000  0.000000      1  \n",
       "1    0.000000  0.000000  0.000000      1  \n",
       "2    0.000000  0.000000  0.000000      0  \n",
       "3    0.000000  0.000000  0.000000      1  \n",
       "4    0.000000  0.000000  0.067552      0  \n",
       "..        ...       ...       ...    ...  \n",
       "175  0.067562  0.156546  0.000000      1  \n",
       "176  0.113882  0.000000  0.046687      0  \n",
       "177  0.000000  0.000000  0.000000      1  \n",
       "178  0.000000  0.000000  0.000000      0  \n",
       "179  0.000000  0.000000  0.000000      0  \n",
       "\n",
       "[180 rows x 863 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign & normalize words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign ranks based on TF-IDF scores \n",
    "def assign_flipped_ranks(row):\n",
    "    ranks = row.rank(method='min', ascending=False)  # Assign ranks (higher score gets lower rank)\n",
    "    max_rank = ranks.max() \n",
    "    if max_rank > 0:\n",
    "        ranks = (max_rank + 1 - ranks) / max_rank #normalize rank to 0-1 scale -> closer to 1 is better rank\n",
    "    ranks[row == 0] = 0  # Assign rank 0 to words not present in the document\n",
    "    return ranks\n",
    "\n",
    "# Apply rank assignment\n",
    "tfidf_ranks_df = tfidf_df.drop(columns=['Genre']).apply(assign_flipped_ranks, axis=1)\n",
    "tfidf_ranks_df['Genre'] = tfidf_df['Genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate DataFrame by genre\n",
    "sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 1].drop(columns=['Genre'])\n",
    "non_sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 0].drop(columns=['Genre'])\n",
    "\n",
    "# Calculate sum rank for each word in each genre\n",
    "sf_agg_ranks = sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "non_sf_agg_ranks = non_sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "# DataFrame for aggregated ranks\n",
    "sf_agg_ranks_df = pd.DataFrame({'Word': sf_agg_ranks.index, 'SF Total Rank': sf_agg_ranks.values})\n",
    "non_sf_agg_ranks_df = pd.DataFrame({'Word': non_sf_agg_ranks.index, 'Non-SF Total Rank': non_sf_agg_ranks.values})\n",
    "\n",
    "agg_ranks_df = pd.merge(sf_agg_ranks_df, non_sf_agg_ranks_df, on='Word', how='outer')\n",
    "agg_ranks_df['Difference'] = agg_ranks_df['SF Total Rank'] - agg_ranks_df['Non-SF Total Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann–Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "p_values = []\n",
    "\n",
    "# Perform the Mann–Whitney U Test for each word\n",
    "for word in agg_ranks_df['Word']:\n",
    "    # Extract the rank values for the word from the SF and Non-SF DataFrames\n",
    "    sf_ranks_word = sf_ranks[word].values\n",
    "    non_sf_ranks_word = non_sf_ranks[word].values\n",
    "\n",
    "    # Perform the Mann–Whitney U Test\n",
    "    stat, p_value = mannwhitneyu(sf_ranks_word, non_sf_ranks_word, alternative='two-sided')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Append result\n",
    "agg_ranks_df['P-Value'] = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>SF Total Rank</th>\n",
       "      <th>Non-SF Total Rank</th>\n",
       "      <th>Difference</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nineteen</td>\n",
       "      <td>22.879862</td>\n",
       "      <td>4.587328</td>\n",
       "      <td>18.292534</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>father</td>\n",
       "      <td>19.169872</td>\n",
       "      <td>4.793815</td>\n",
       "      <td>14.376057</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life</td>\n",
       "      <td>20.845270</td>\n",
       "      <td>7.944148</td>\n",
       "      <td>12.901122</td>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mother</td>\n",
       "      <td>17.702600</td>\n",
       "      <td>5.590842</td>\n",
       "      <td>12.111758</td>\n",
       "      <td>0.002665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>20.001320</td>\n",
       "      <td>10.022805</td>\n",
       "      <td>9.978515</td>\n",
       "      <td>0.014133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>does</td>\n",
       "      <td>6.430369</td>\n",
       "      <td>3.598846</td>\n",
       "      <td>2.831523</td>\n",
       "      <td>0.101245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>known</td>\n",
       "      <td>6.147119</td>\n",
       "      <td>3.417795</td>\n",
       "      <td>2.729323</td>\n",
       "      <td>0.091101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>times</td>\n",
       "      <td>7.045433</td>\n",
       "      <td>4.321257</td>\n",
       "      <td>2.724177</td>\n",
       "      <td>0.007497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>law</td>\n",
       "      <td>7.245456</td>\n",
       "      <td>4.677478</td>\n",
       "      <td>2.567978</td>\n",
       "      <td>0.053788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>hour</td>\n",
       "      <td>7.104443</td>\n",
       "      <td>4.624788</td>\n",
       "      <td>2.479655</td>\n",
       "      <td>0.132415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  SF Total Rank  Non-SF Total Rank  Difference   P-Value\n",
       "0    nineteen      22.879862           4.587328   18.292534  0.000002\n",
       "1      father      19.169872           4.793815   14.376057  0.000011\n",
       "2        life      20.845270           7.944148   12.901122  0.000733\n",
       "3      mother      17.702600           5.590842   12.111758  0.002665\n",
       "4      family      20.001320          10.022805    9.978515  0.014133\n",
       "..        ...            ...                ...         ...       ...\n",
       "102      does       6.430369           3.598846    2.831523  0.101245\n",
       "103     known       6.147119           3.417795    2.729323  0.091101\n",
       "104     times       7.045433           4.321257    2.724177  0.007497\n",
       "105       law       7.245456           4.677478    2.567978  0.053788\n",
       "106      hour       7.104443           4.624788    2.479655  0.132415\n",
       "\n",
       "[107 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list = agg_ranks_df[(agg_ranks_df['Difference'] > 2) & (agg_ranks_df['P-Value'] < 0.15)].sort_values(by='Difference', ascending=False).reset_index(drop=True)\n",
    "filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0191149427823145"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list['Difference'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping documents with all-zero vectorization (no matching terms in top list): [ 60 149]\n",
      "Training set size: 124\n",
      "Test set size: 54\n",
      "Class distribution in training set: label\n",
      "1    0.508065\n",
      "0    0.491935\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in test set: label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_terms = filter_list['Word'].values\n",
    "\n",
    "# Vectorize the original corpus\n",
    "vectorizer = TfidfVectorizer(vocabulary=top_terms)  # Restrict vectorization to top terms\n",
    "selected_features = vectorizer.fit_transform(corpus_df['document'])  # Apply vectorizer to original documents\n",
    "\n",
    "\n",
    "# Call out documents with all zero\n",
    "zero_vector_docs = np.where(selected_features.toarray().sum(axis=1) == 0)[0]  # Find indices of documents with all-zero vectors\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Dropping documents with all-zero vectorization (no matching terms in top list): {zero_vector_docs}\")\n",
    "    select_corpus_df = corpus_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    selected_features = vectorizer.fit_transform(select_corpus_df['document'])  # Re-vectorize without dropped docs\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "# Create DataFrame with selected features (top terms)\n",
    "selected_df = pd.DataFrame(selected_features.toarray(), columns=top_terms)\n",
    "\n",
    "# Add genre labels \n",
    "selected_df['label'] = select_corpus_df['label']\n",
    "\n",
    "# Prepare X and y for training\n",
    "X = selected_df.drop(columns='label')\n",
    "y = selected_df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Check the balanced split\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "print(\"Class distribution in training set:\", y_train.value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       0.73      0.70      0.72        27\n",
      "Science Fiction & Fantasy       0.71      0.74      0.73        27\n",
      "\n",
      "                 accuracy                           0.72        54\n",
      "                macro avg       0.72      0.72      0.72        54\n",
      "             weighted avg       0.72      0.72      0.72        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.49489660793900386\n",
      "Adjusted Threshold Test Set Performance:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       0.76      0.70      0.73        27\n",
      "Science Fiction & Fantasy       0.72      0.78      0.75        27\n",
      "\n",
      "                 accuracy                           0.74        54\n",
      "                macro avg       0.74      0.74      0.74        54\n",
      "             weighted avg       0.74      0.74      0.74        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model using the training set\n",
    "final_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_probs = final_model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "# Calculate precision-recall pairs for different thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Choose optimized threshold \n",
    "best_threshold_index = np.argmax(2 * (precisions * recalls) / (precisions + recalls))\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "\n",
    "# Make predictions using the new threshold\n",
    "y_pred_adj = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate performance using the adjusted threshold\n",
    "print(\"Adjusted Threshold Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_adj, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Predictive Terms for Science Fiction & Fantasy:\n",
      "        Term  Coefficient\n",
      "0        tom     0.936596\n",
      "1     father     0.844209\n",
      "2   nineteen     0.794681\n",
      "3       song     0.722070\n",
      "4      began     0.691467\n",
      "5       york     0.667033\n",
      "6      wrote     0.660687\n",
      "7     mother     0.654407\n",
      "8     school     0.643468\n",
      "9      young     0.628402\n",
      "10    unable     0.624175\n",
      "11   feeling     0.622591\n",
      "12     loved     0.586434\n",
      "13     stuck     0.574282\n",
      "14  children     0.571816\n",
      "15      ride     0.567902\n",
      "16     child     0.566299\n",
      "17  fourteen     0.537479\n",
      "18   husband     0.537436\n",
      "19     quite     0.528955\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Term': X.columns,\n",
    "    'Coefficient': logreg.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top Predictive Terms for Science Fiction & Fantasy:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reserved test set\n",
    "reserved_df = pd.read_csv('../data/corpus/reserved_test_pred.csv')\n",
    "\n",
    "original_reserved_df = reserved_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1 documents with all-zero vectorization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the reserved test set\n",
    "reserved_features = vectorizer.transform(reserved_df['document'])  # Apply trained vectorizer\n",
    "\n",
    "# Cull out documents with all-zero vectorization\n",
    "zero_vector_docs = np.where(reserved_features.toarray().sum(axis=1) == 0)[0]  \n",
    "\n",
    "# Store ASINs of removed documents \n",
    "removed_asins = reserved_df.iloc[zero_vector_docs]['asin'].tolist()\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Removing {len(zero_vector_docs)} documents with all-zero vectorization.\")\n",
    "    reserved_df = reserved_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    reserved_features = vectorizer.transform(reserved_df['document'])  # Re-vectorize remaining documents\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "#Predict probabilities using the final logistic regression model\n",
    "reserved_probs = final_model.predict_proba(reserved_features)[:, 1]  # Probability for class 1 (main genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the reserved_df\n",
    "main_genre = \"Biographies\" \n",
    "reserved_df[f\"{main_genre}_Prob\"] = reserved_probs.round(2)\n",
    "\n",
    "# Reinsert removed documents with placeholder values\n",
    "original_reserved_df[f\"{main_genre}_Prob\"] = None  # Initialize the probability column with None\n",
    "original_reserved_df.loc[\n",
    "    original_reserved_df['asin'].isin(reserved_df['asin']), \n",
    "    f\"{main_genre}_Prob\"\n",
    "] = reserved_df[f\"{main_genre}_Prob\"].values\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "original_reserved_df.to_csv('../data/corpus/reserved_test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
