{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         asin                                           document  label\n",
      "0  B00D2WFL2U  but candles were scarcer than food then and i ...      1\n",
      "1  B015NL50YQ  jellicoe his voice was clipped precise my coun...      1\n",
      "2  B002V5CVJU  equivocal worshipped in theatre and boudoir sc...      0\n",
      "3  B07R7432SV  although she'd been clean for two years after ...      1\n",
      "4  B07B3YMKXD  in the early nineteen forties this little boy ...      0\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.read_csv('../data/corpus/Science_Fiction_&_Fantasy.csv')\n",
    "print(corpus_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Sum Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract documents and labels from the DataFrame\n",
    "corpus = corpus_df['document']\n",
    "labels = corpus_df['label']\n",
    "\n",
    "# Calculate TF-IDF \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.5, min_df=10, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "terms_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create DataFrame for TF-IDF scores with labels\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=terms_tfidf)\n",
    "tfidf_df['Genre'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>added</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>ahead</th>\n",
       "      <th>air</th>\n",
       "      <th>alien</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051806</td>\n",
       "      <td>0.071916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095867</td>\n",
       "      <td>0.110643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 871 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ability  able  action  actually     added  age       ago     ahead  \\\n",
       "0        0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "1        0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "2        0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "3        0.0   0.0     0.0       0.0  0.070097  0.0  0.051583  0.000000   \n",
       "4        0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "..       ...   ...     ...       ...       ...  ...       ...       ...   \n",
       "175      0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "176      0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "177      0.0   0.0     0.0       0.0  0.000000  0.0  0.078431  0.000000   \n",
       "178      0.0   0.0     0.0       0.0  0.000000  0.0  0.000000  0.000000   \n",
       "179      0.0   0.0     0.0       0.0  0.000000  0.0  0.095867  0.110643   \n",
       "\n",
       "          air     alien  ...  written     wrong  yeah      year     years  \\\n",
       "0    0.054711  0.000000  ...      0.0  0.000000   0.0  0.000000  0.000000   \n",
       "1    0.000000  0.000000  ...      0.0  0.000000   0.0  0.000000  0.000000   \n",
       "2    0.000000  0.000000  ...      0.0  0.000000   0.0  0.051806  0.071916   \n",
       "3    0.000000  0.000000  ...      0.0  0.054104   0.0  0.000000  0.175044   \n",
       "4    0.000000  0.000000  ...      0.0  0.000000   0.0  0.000000  0.000000   \n",
       "..        ...       ...  ...      ...       ...   ...       ...       ...   \n",
       "175  0.000000  0.000000  ...      0.0  0.000000   0.0  0.000000  0.000000   \n",
       "176  0.000000  0.000000  ...      0.0  0.000000   0.0  0.000000  0.038709   \n",
       "177  0.000000  0.000000  ...      0.0  0.000000   0.0  0.000000  0.000000   \n",
       "178  0.068177  0.000000  ...      0.0  0.000000   0.0  0.000000  0.000000   \n",
       "179  0.000000  0.133327  ...      0.0  0.000000   0.0  0.000000  0.065064   \n",
       "\n",
       "       yellow  yes  york     young  Genre  \n",
       "0    0.000000  0.0   0.0  0.000000      1  \n",
       "1    0.000000  0.0   0.0  0.000000      1  \n",
       "2    0.000000  0.0   0.0  0.000000      0  \n",
       "3    0.000000  0.0   0.0  0.000000      1  \n",
       "4    0.000000  0.0   0.0  0.066982      0  \n",
       "..        ...  ...   ...       ...    ...  \n",
       "175  0.000000  0.0   0.0  0.000000      1  \n",
       "176  0.000000  0.0   0.0  0.205438      0  \n",
       "177  0.102157  0.0   0.0  0.141252      1  \n",
       "178  0.000000  0.0   0.0  0.117065      0  \n",
       "179  0.000000  0.0   0.0  0.000000      0  \n",
       "\n",
       "[180 rows x 871 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign & normalize words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign ranks based on TF-IDF scores \n",
    "def assign_flipped_ranks(row):\n",
    "    ranks = row.rank(method='min', ascending=False)  # Assign ranks (higher score gets lower rank)\n",
    "    max_rank = ranks.max() \n",
    "    if max_rank > 0:\n",
    "        ranks = (max_rank + 1 - ranks) / max_rank #normalize rank to 0-1 scale -> closer to 1 is better rank\n",
    "    ranks[row == 0] = 0  # Assign rank 0 to words not present in the document\n",
    "    return ranks\n",
    "\n",
    "# Apply rank assignment\n",
    "tfidf_ranks_df = tfidf_df.drop(columns=['Genre']).apply(assign_flipped_ranks, axis=1)\n",
    "tfidf_ranks_df['Genre'] = tfidf_df['Genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate DataFrame by genre\n",
    "sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 1].drop(columns=['Genre'])\n",
    "non_sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 0].drop(columns=['Genre'])\n",
    "\n",
    "# Calculate sum rank for each word in each genre\n",
    "sf_agg_ranks = sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "non_sf_agg_ranks = non_sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "# DataFrame for aggregated ranks\n",
    "sf_agg_ranks_df = pd.DataFrame({'Word': sf_agg_ranks.index, 'SF Total Rank': sf_agg_ranks.values})\n",
    "non_sf_agg_ranks_df = pd.DataFrame({'Word': non_sf_agg_ranks.index, 'Non-SF Total Rank': non_sf_agg_ranks.values})\n",
    "\n",
    "agg_ranks_df = pd.merge(sf_agg_ranks_df, non_sf_agg_ranks_df, on='Word', how='outer')\n",
    "agg_ranks_df['Difference'] = agg_ranks_df['SF Total Rank'] - agg_ranks_df['Non-SF Total Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann–Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "p_values = []\n",
    "\n",
    "# Perform the Mann–Whitney U Test for each word\n",
    "for word in agg_ranks_df['Word']:\n",
    "    # Extract the rank values for the word from the SF and Non-SF DataFrames\n",
    "    sf_ranks_word = sf_ranks[word].values\n",
    "    non_sf_ranks_word = non_sf_ranks[word].values\n",
    "\n",
    "    # Perform the Mann–Whitney U Test\n",
    "    stat, p_value = mannwhitneyu(sf_ranks_word, non_sf_ranks_word, alternative='two-sided')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Append result\n",
    "agg_ranks_df['P-Value'] = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>SF Total Rank</th>\n",
       "      <th>Non-SF Total Rank</th>\n",
       "      <th>Difference</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walls</td>\n",
       "      <td>11.094503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.094503</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>light</td>\n",
       "      <td>12.777807</td>\n",
       "      <td>3.381029</td>\n",
       "      <td>9.396778</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dark</td>\n",
       "      <td>15.456163</td>\n",
       "      <td>6.455115</td>\n",
       "      <td>9.001048</td>\n",
       "      <td>0.004652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gods</td>\n",
       "      <td>8.555831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.555831</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shadow</td>\n",
       "      <td>8.536379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.536379</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>voice</td>\n",
       "      <td>9.329313</td>\n",
       "      <td>5.174995</td>\n",
       "      <td>4.154318</td>\n",
       "      <td>0.021374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>land</td>\n",
       "      <td>7.222127</td>\n",
       "      <td>3.220168</td>\n",
       "      <td>4.001959</td>\n",
       "      <td>0.023573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>laughed</td>\n",
       "      <td>6.791881</td>\n",
       "      <td>2.949879</td>\n",
       "      <td>3.842002</td>\n",
       "      <td>0.044620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>edge</td>\n",
       "      <td>6.834207</td>\n",
       "      <td>2.992428</td>\n",
       "      <td>3.841779</td>\n",
       "      <td>0.046654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>past</td>\n",
       "      <td>8.650103</td>\n",
       "      <td>5.464706</td>\n",
       "      <td>3.185398</td>\n",
       "      <td>0.030213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  SF Total Rank  Non-SF Total Rank  Difference   P-Value\n",
       "0     walls      11.094503           0.000000   11.094503  0.000005\n",
       "1     light      12.777807           3.381029    9.396778  0.000584\n",
       "2      dark      15.456163           6.455115    9.001048  0.004652\n",
       "3      gods       8.555831           0.000000    8.555831  0.001197\n",
       "4    shadow       8.536379           0.000000    8.536379  0.001197\n",
       "..      ...            ...                ...         ...       ...\n",
       "67    voice       9.329313           5.174995    4.154318  0.021374\n",
       "68     land       7.222127           3.220168    4.001959  0.023573\n",
       "69  laughed       6.791881           2.949879    3.842002  0.044620\n",
       "70     edge       6.834207           2.992428    3.841779  0.046654\n",
       "71     past       8.650103           5.464706    3.185398  0.030213\n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list = agg_ranks_df[(agg_ranks_df['Difference'] > 3) & (agg_ranks_df['P-Value'] < 0.05)].sort_values(by='Difference', ascending=False).reset_index(drop=True)\n",
    "filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.89045446075564"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list['Difference'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping documents with all-zero vectorization (no matching terms in top list): [13 33 83 84 90]\n",
      "Training set size: 122\n",
      "Test set size: 53\n",
      "Class distribution in training set: label\n",
      "1    0.508197\n",
      "0    0.491803\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in test set: label\n",
      "1    0.509434\n",
      "0    0.490566\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_terms = filter_list['Word'].values\n",
    "\n",
    "# Vectorize the original corpus\n",
    "vectorizer = TfidfVectorizer(vocabulary=top_terms)  # Restrict vectorization to top terms\n",
    "selected_features = vectorizer.fit_transform(corpus_df['document'])  # Apply vectorizer to original documents\n",
    "\n",
    "\n",
    "# Cull out documents with all zero\n",
    "zero_vector_docs = np.where(selected_features.toarray().sum(axis=1) == 0)[0]  # Find indices of documents with all-zero vectors\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Dropping documents with all-zero vectorization (no matching terms in top list): {zero_vector_docs}\")\n",
    "    select_corpus_df = corpus_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    selected_features = vectorizer.fit_transform(select_corpus_df['document'])  # Re-vectorize without dropped docs\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "\n",
    "# Create DataFrame with selected features (top terms)\n",
    "selected_df = pd.DataFrame(selected_features.toarray(), columns=top_terms)\n",
    "\n",
    "# Add genre labels \n",
    "selected_df['label'] = select_corpus_df['label']\n",
    "\n",
    "# Prepare X and y for training\n",
    "X = selected_df.drop(columns='label')\n",
    "y = selected_df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=60)\n",
    "\n",
    "# Check the balanced split\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "print(\"Class distribution in training set:\", y_train.value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       0.71      0.77      0.74        26\n",
      "Science Fiction & Fantasy       0.76      0.70      0.73        27\n",
      "\n",
      "                 accuracy                           0.74        53\n",
      "                macro avg       0.74      0.74      0.74        53\n",
      "             weighted avg       0.74      0.74      0.74        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, C = 2)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4824012416738424\n",
      "Adjusted Threshold Test Set Performance:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       0.86      0.69      0.77        26\n",
      "Science Fiction & Fantasy       0.75      0.89      0.81        27\n",
      "\n",
      "                 accuracy                           0.79        53\n",
      "                macro avg       0.80      0.79      0.79        53\n",
      "             weighted avg       0.80      0.79      0.79        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model using the training set\n",
    "final_model = LogisticRegression(max_iter=1000, random_state=42, C = 2)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_probs = final_model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "# Calculate precision-recall pairs for different thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Choose optimized threshold \n",
    "best_threshold_index = np.argmax(2 * (precisions * recalls) / (precisions + recalls))\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "\n",
    "# Make predictions using the new threshold\n",
    "y_pred_adj = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate performance using the adjusted threshold\n",
    "print(\"Adjusted Threshold Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_adj, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Predictive Terms for Science Fiction & Fantasy:\n",
      "       Term  Coefficient\n",
      "0      gods     1.257359\n",
      "1      body     0.937182\n",
      "2   watched     0.907494\n",
      "3    joined     0.861240\n",
      "4     magic     0.854315\n",
      "5     metal     0.850970\n",
      "6    shadow     0.834027\n",
      "7     walls     0.775238\n",
      "8      wind     0.736976\n",
      "9    planet     0.698555\n",
      "10     skin     0.694276\n",
      "11     arms     0.680673\n",
      "12    swept     0.652652\n",
      "13      air     0.637564\n",
      "14    flesh     0.592339\n",
      "15     hurt     0.590782\n",
      "16    enemy     0.586606\n",
      "17    mouth     0.577916\n",
      "18     blue     0.574546\n",
      "19    sword     0.530381\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Term': X.columns,\n",
    "    'Coefficient': logreg.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top Predictive Terms for Science Fiction & Fantasy:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reserved test set\n",
    "reserved_df = pd.read_csv('../data/corpus/reserved_test_set.csv')\n",
    "\n",
    "original_reserved_df = reserved_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 7 documents with all-zero vectorization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the reserved test set\n",
    "reserved_features = vectorizer.transform(reserved_df['document'])  # Apply trained vectorizer\n",
    "\n",
    "# Cull out documents with all-zero vectorization\n",
    "zero_vector_docs = np.where(reserved_features.toarray().sum(axis=1) == 0)[0]  \n",
    "\n",
    "# Store ASINs of removed documents \n",
    "removed_asins = reserved_df.iloc[zero_vector_docs]['asin'].tolist()\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Removing {len(zero_vector_docs)} documents with all-zero vectorization.\")\n",
    "    reserved_df = reserved_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    #reserved_features = reserved_features[~np.isin(range(len(original_reserved_df)), zero_vector_docs)]  # Update features\n",
    "    reserved_features = vectorizer.transform(reserved_df['document'])  # Re-vectorize remaining documents\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "#Predict probabilities using the final logistic regression model\n",
    "reserved_probs = final_model.predict_proba(reserved_features)[:, 1]  # Probability for class 1 (main genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the reserved_df\n",
    "main_genre = \"Science_Fiction\" \n",
    "reserved_df[f\"{main_genre}_Prob\"] = reserved_probs.round(2)\n",
    "\n",
    "# Reinsert removed documents with placeholder values\n",
    "original_reserved_df[f\"{main_genre}_Prob\"] = None  # Initialize the probability column with None\n",
    "original_reserved_df.loc[\n",
    "    original_reserved_df['asin'].isin(reserved_df['asin']), \n",
    "    f\"{main_genre}_Prob\"\n",
    "] = reserved_df[f\"{main_genre}_Prob\"].values\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "original_reserved_df.to_csv('../data/corpus/reserved_test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
