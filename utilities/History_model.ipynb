{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         asin                                           document  label\n",
      "0  B00F8JE9ZA  our nation and the world breathed a sigh of re...      1\n",
      "1  B07BN1459L  he took a far more active role in saving both ...      1\n",
      "2  B07KL64VDH  chapter two identifying what you want the impo...      0\n",
      "3  B00QFSRWWU  next time you're in the city so nice they name...      1\n",
      "4  B002ZP8M44  i have been asked why i as a latina am writing...      0\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.read_csv('../data/corpus/History.csv')\n",
    "print(corpus_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Sum Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract documents and labels from the DataFrame\n",
    "corpus = corpus_df['document']\n",
    "labels = corpus_df['label']\n",
    "\n",
    "# Calculate TF-IDF \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.5, min_df=10, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "terms_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create DataFrame for TF-IDF scores with labels\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=terms_tfidf)\n",
    "tfidf_df['Genre'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>according</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actions</th>\n",
       "      <th>actually</th>\n",
       "      <th>added</th>\n",
       "      <th>advance</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049671</td>\n",
       "      <td>0.046961</td>\n",
       "      <td>0.099341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086250</td>\n",
       "      <td>0.163091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         able  according       act    action   actions  actually     added  \\\n",
       "0    0.000000   0.049671  0.046961  0.099341  0.000000  0.000000  0.000000   \n",
       "1    0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2    0.035199   0.000000  0.000000  0.000000  0.000000  0.039249  0.000000   \n",
       "3    0.000000   0.000000  0.000000  0.000000  0.000000  0.059613  0.000000   \n",
       "4    0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..        ...        ...       ...       ...       ...       ...       ...   \n",
       "175  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "176  0.000000   0.086250  0.163091  0.000000  0.000000  0.000000  0.086250   \n",
       "177  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "178  0.000000   0.000000  0.000000  0.000000  0.073845  0.000000  0.075305   \n",
       "179  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     advance       age  ago  ...   written  wrong  wrote      yeah      year  \\\n",
       "0        0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "1        0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "2        0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "3        0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "4        0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "..       ...       ...  ...  ...       ...    ...    ...       ...       ...   \n",
       "175      0.0  0.118209  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "176      0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.057957   \n",
       "177      0.0  0.000000  0.0  ...  0.192724    0.0    0.0  0.000000  0.000000   \n",
       "178      0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.080407  0.000000   \n",
       "179      0.0  0.000000  0.0  ...  0.000000    0.0    0.0  0.000000  0.000000   \n",
       "\n",
       "        years       yes      york     young  Genre  \n",
       "0    0.023704  0.000000  0.000000  0.036491      1  \n",
       "1    0.040958  0.000000  0.000000  0.000000      1  \n",
       "2    0.000000  0.000000  0.000000  0.000000      0  \n",
       "3    0.033985  0.000000  0.252403  0.000000      1  \n",
       "4    0.037536  0.000000  0.000000  0.000000      0  \n",
       "..        ...       ...       ...       ...    ...  \n",
       "175  0.000000  0.000000  0.000000  0.000000      1  \n",
       "176  0.000000  0.000000  0.000000  0.000000      0  \n",
       "177  0.000000  0.000000  0.000000  0.000000      1  \n",
       "178  0.000000  0.066727  0.000000  0.000000      0  \n",
       "179  0.000000  0.000000  0.000000  0.000000      0  \n",
       "\n",
       "[180 rows x 845 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign & normalize words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign ranks based on TF-IDF scores \n",
    "def assign_flipped_ranks(row):\n",
    "    ranks = row.rank(method='min', ascending=False)  # Assign ranks (higher score gets lower rank)\n",
    "    max_rank = ranks.max() \n",
    "    if max_rank > 0:\n",
    "        ranks = (max_rank + 1 - ranks) / max_rank #normalize rank to 0-1 scale -> closer to 1 is better rank\n",
    "    ranks[row == 0] = 0  # Assign rank 0 to words not present in the document\n",
    "    return ranks\n",
    "\n",
    "# Apply rank assignment\n",
    "tfidf_ranks_df = tfidf_df.drop(columns=['Genre']).apply(assign_flipped_ranks, axis=1)\n",
    "tfidf_ranks_df['Genre'] = tfidf_df['Genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate DataFrame by genre\n",
    "sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 1].drop(columns=['Genre'])\n",
    "non_sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 0].drop(columns=['Genre'])\n",
    "\n",
    "# Calculate sum rank for each word in each genre\n",
    "sf_agg_ranks = sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "non_sf_agg_ranks = non_sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "# DataFrame for aggregated ranks\n",
    "sf_agg_ranks_df = pd.DataFrame({'Word': sf_agg_ranks.index, 'SF Total Rank': sf_agg_ranks.values})\n",
    "non_sf_agg_ranks_df = pd.DataFrame({'Word': non_sf_agg_ranks.index, 'Non-SF Total Rank': non_sf_agg_ranks.values})\n",
    "\n",
    "agg_ranks_df = pd.merge(sf_agg_ranks_df, non_sf_agg_ranks_df, on='Word', how='outer')\n",
    "agg_ranks_df['Difference'] = agg_ranks_df['SF Total Rank'] - agg_ranks_df['Non-SF Total Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann–Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "p_values = []\n",
    "\n",
    "# Perform the Mann–Whitney U Test for each word\n",
    "for word in agg_ranks_df['Word']:\n",
    "    # Extract the rank values for the word from the SF and Non-SF DataFrames\n",
    "    sf_ranks_word = sf_ranks[word].values\n",
    "    non_sf_ranks_word = non_sf_ranks[word].values\n",
    "\n",
    "    # Perform the Mann–Whitney U Test\n",
    "    stat, p_value = mannwhitneyu(sf_ranks_word, non_sf_ranks_word, alternative='two-sided')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Append result\n",
    "agg_ranks_df['P-Value'] = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>SF Total Rank</th>\n",
       "      <th>Non-SF Total Rank</th>\n",
       "      <th>Difference</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>war</td>\n",
       "      <td>29.103534</td>\n",
       "      <td>4.812152</td>\n",
       "      <td>24.291382</td>\n",
       "      <td>6.258497e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>history</td>\n",
       "      <td>20.002698</td>\n",
       "      <td>2.344067</td>\n",
       "      <td>17.658631</td>\n",
       "      <td>6.382283e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>20.939631</td>\n",
       "      <td>3.661125</td>\n",
       "      <td>17.278506</td>\n",
       "      <td>1.322949e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>21.192140</td>\n",
       "      <td>5.886474</td>\n",
       "      <td>15.305665</td>\n",
       "      <td>8.562058e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>century</td>\n",
       "      <td>15.164339</td>\n",
       "      <td>1.086311</td>\n",
       "      <td>14.078027</td>\n",
       "      <td>2.817258e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>vast</td>\n",
       "      <td>7.171570</td>\n",
       "      <td>2.019517</td>\n",
       "      <td>5.152053</td>\n",
       "      <td>1.572039e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ninety</td>\n",
       "      <td>8.906931</td>\n",
       "      <td>3.824966</td>\n",
       "      <td>5.081965</td>\n",
       "      <td>1.934698e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>caused</td>\n",
       "      <td>6.412800</td>\n",
       "      <td>1.375403</td>\n",
       "      <td>5.037397</td>\n",
       "      <td>2.969431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>number</td>\n",
       "      <td>9.055500</td>\n",
       "      <td>4.225113</td>\n",
       "      <td>4.830388</td>\n",
       "      <td>9.739089e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>force</td>\n",
       "      <td>7.862531</td>\n",
       "      <td>3.077929</td>\n",
       "      <td>4.784602</td>\n",
       "      <td>2.485764e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  SF Total Rank  Non-SF Total Rank  Difference       P-Value\n",
       "0         war      29.103534           4.812152   24.291382  6.258497e-09\n",
       "1     history      20.002698           2.344067   17.658631  6.382283e-07\n",
       "2    american      20.939631           3.661125   17.278506  1.322949e-05\n",
       "3       great      21.192140           5.886474   15.305665  8.562058e-05\n",
       "4     century      15.164339           1.086311   14.078027  2.817258e-06\n",
       "..        ...            ...                ...         ...           ...\n",
       "110      vast       7.171570           2.019517    5.152053  1.572039e-02\n",
       "111    ninety       8.906931           3.824966    5.081965  1.934698e-02\n",
       "112    caused       6.412800           1.375403    5.037397  2.969431e-02\n",
       "113    number       9.055500           4.225113    4.830388  9.739089e-03\n",
       "114     force       7.862531           3.077929    4.784602  2.485764e-02\n",
       "\n",
       "[115 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list = agg_ranks_df[(agg_ranks_df['Difference'] > 4) & (agg_ranks_df['P-Value'] < 0.03)].sort_values(by='Difference', ascending=False).reset_index(drop=True)\n",
    "filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.240091802088993"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list['Difference'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping documents with all-zero vectorization (no matching terms in top list): [ 56 140]\n",
      "Training set size: 124\n",
      "Test set size: 54\n",
      "Class distribution in training set: label\n",
      "1    0.508065\n",
      "0    0.491935\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in test set: label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_terms = filter_list['Word'].values\n",
    "\n",
    "# Vectorize the original corpus\n",
    "vectorizer = TfidfVectorizer(vocabulary=top_terms)  # Restrict vectorization to top terms\n",
    "selected_features = vectorizer.fit_transform(corpus_df['document'])  # Apply vectorizer to original documents\n",
    "\n",
    "\n",
    "# Call out documents with all zero\n",
    "zero_vector_docs = np.where(selected_features.toarray().sum(axis=1) == 0)[0]  # Find indices of documents with all-zero vectors\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Dropping documents with all-zero vectorization (no matching terms in top list): {zero_vector_docs}\")\n",
    "    select_corpus_df = corpus_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    selected_features = vectorizer.fit_transform(select_corpus_df['document'])  # Re-vectorize without dropped docs\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "\n",
    "# Create DataFrame with selected features (top terms)\n",
    "selected_df = pd.DataFrame(selected_features.toarray(), columns=top_terms)\n",
    "\n",
    "# Add genre labels \n",
    "selected_df['label'] = select_corpus_df['label']\n",
    "\n",
    "# Prepare X and y for training\n",
    "X = selected_df.drop(columns='label')\n",
    "y = selected_df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Check the balanced split\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "print(\"Class distribution in training set:\", y_train.value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       0.89      0.89      0.89        27\n",
      "Science Fiction & Fantasy       0.89      0.89      0.89        27\n",
      "\n",
      "                 accuracy                           0.89        54\n",
      "                macro avg       0.89      0.89      0.89        54\n",
      "             weighted avg       0.89      0.89      0.89        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, C = 2)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4689019400101556\n",
      "Adjusted Threshold Test Set Performance:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       0.96      0.85      0.90        27\n",
      "Science Fiction & Fantasy       0.87      0.96      0.91        27\n",
      "\n",
      "                 accuracy                           0.91        54\n",
      "                macro avg       0.91      0.91      0.91        54\n",
      "             weighted avg       0.91      0.91      0.91        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model using the training set\n",
    "final_model = LogisticRegression(max_iter=1000, random_state=42, C = 2)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_probs = final_model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "# Calculate precision-recall pairs for different thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Choose optimized threshold \n",
    "best_threshold_index = np.argmax(2 * (precisions * recalls) / (precisions + recalls))\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "\n",
    "# Make predictions using the new threshold\n",
    "y_pred_adj = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate performance using the adjusted threshold\n",
    "print(\"Adjusted Threshold Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_adj, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Predictive Terms for Science Fiction & Fantasy:\n",
      "         Term  Coefficient\n",
      "0      german     1.686211\n",
      "1         war     1.612857\n",
      "2       roman     1.558903\n",
      "3        rome     1.453823\n",
      "4      europe     1.428229\n",
      "5      modern     1.400102\n",
      "6      eighty     1.353663\n",
      "7       south     1.283349\n",
      "8    virginia     1.261024\n",
      "9    eighteen     1.203458\n",
      "10     nation     1.190980\n",
      "11       west     1.185050\n",
      "12     france     1.138338\n",
      "13    western     1.106020\n",
      "14      enemy     1.075418\n",
      "15   directly     1.019639\n",
      "16        lee     1.006930\n",
      "17     empire     0.977718\n",
      "18  americans     0.968687\n",
      "19      april     0.953855\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Term': X.columns,\n",
    "    'Coefficient': logreg.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top Predictive Terms for Science Fiction & Fantasy:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reserved test set\n",
    "reserved_df = pd.read_csv('../data/corpus/reserved_test_pred.csv')\n",
    "\n",
    "original_reserved_df = reserved_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 2 documents with all-zero vectorization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the reserved test set\n",
    "reserved_features = vectorizer.transform(reserved_df['document'])  # Apply trained vectorizer\n",
    "\n",
    "# Cull out documents with all-zero vectorization\n",
    "zero_vector_docs = np.where(reserved_features.toarray().sum(axis=1) == 0)[0]  \n",
    "\n",
    "# Store ASINs of removed documents \n",
    "removed_asins = reserved_df.iloc[zero_vector_docs]['asin'].tolist()\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Removing {len(zero_vector_docs)} documents with all-zero vectorization.\")\n",
    "    reserved_df = reserved_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    reserved_features = vectorizer.transform(reserved_df['document'])  # Re-vectorize remaining documents\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "#Predict probabilities using the final logistic regression model\n",
    "reserved_probs = final_model.predict_proba(reserved_features)[:, 1]  # Probability for class 1 (main genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the reserved_df\n",
    "main_genre = \"History\" \n",
    "reserved_df[f\"{main_genre}_Prob\"] = reserved_probs.round(2)\n",
    "\n",
    "# Reinsert removed documents with placeholder values\n",
    "original_reserved_df[f\"{main_genre}_Prob\"] = None  # Initialize the probability column with None\n",
    "original_reserved_df.loc[\n",
    "    original_reserved_df['asin'].isin(reserved_df['asin']), \n",
    "    f\"{main_genre}_Prob\"\n",
    "] = reserved_df[f\"{main_genre}_Prob\"].values\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "original_reserved_df.to_csv('../data/corpus/reserved_test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
