{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         asin                                           document  label\n",
      "0  B07MM6CM86  or that many individual contributors rely on t...      1\n",
      "1  B01N7J3RQ6  country given that business and india has tend...      1\n",
      "2  B00IPNN1XW  a lifetime is embedded it does not float free ...      0\n",
      "3  B072KL8WX6  written by juliet adams f c i p d technical ed...      1\n",
      "4  B00C3GZ8Y2  nowhere we chatted for awhile all i wanted to ...      0\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.read_csv('../data/corpus/Business_&_Careers.csv')\n",
    "print(corpus_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Sum Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract documents and labels from the DataFrame\n",
    "corpus = corpus_df['document']\n",
    "labels = corpus_df['label']\n",
    "\n",
    "# Calculate TF-IDF \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.5, min_df=10, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "terms_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create DataFrame for TF-IDF scores with labels\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=terms_tfidf)\n",
    "tfidf_df['Genre'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>achieve</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>advantage</th>\n",
       "      <th>advice</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.074272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056594</td>\n",
       "      <td>0.056594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.101739</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120872</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.061752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability      able  absolutely  account   achieve      act  action  \\\n",
       "0    0.000000  0.035576    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "1    0.000000  0.048405    0.000000      0.0  0.063921  0.00000     0.0   \n",
       "2    0.000000  0.000000    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "3    0.000000  0.000000    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "4    0.000000  0.000000    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "..        ...       ...         ...      ...       ...      ...     ...   \n",
       "175  0.000000  0.000000    0.000000      0.0  0.000000  0.06491     0.0   \n",
       "176  0.000000  0.000000    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "177  0.000000  0.000000    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "178  0.000000  0.000000    0.076328      0.0  0.000000  0.00000     0.0   \n",
       "179  0.061752  0.000000    0.000000      0.0  0.000000  0.00000     0.0   \n",
       "\n",
       "     actually  advantage    advice  ...   writing   written     wrong  wrote  \\\n",
       "0    0.000000        0.0  0.000000  ...  0.000000  0.042452  0.000000    0.0   \n",
       "1    0.050046        0.0  0.000000  ...  0.000000  0.000000  0.000000    0.0   \n",
       "2    0.000000        0.0  0.000000  ...  0.159333  0.000000  0.000000    0.0   \n",
       "3    0.000000        0.0  0.061474  ...  0.056594  0.056594  0.000000    0.0   \n",
       "4    0.000000        0.0  0.071503  ...  0.065828  0.000000  0.000000    0.0   \n",
       "..        ...        ...       ...  ...       ...       ...       ...    ...   \n",
       "175  0.055385        0.0  0.000000  ...  0.000000  0.000000  0.000000    0.0   \n",
       "176  0.000000        0.0  0.000000  ...  0.000000  0.000000  0.000000    0.0   \n",
       "177  0.000000        0.0  0.000000  ...  0.000000  0.000000  0.055152    0.0   \n",
       "178  0.000000        0.0  0.000000  ...  0.000000  0.000000  0.000000    0.0   \n",
       "179  0.000000        0.0  0.000000  ...  0.000000  0.000000  0.000000    0.0   \n",
       "\n",
       "        yeah      year     years       yes     young  Genre  \n",
       "0    0.00000  0.000000  0.000000  0.000000  0.000000      1  \n",
       "1    0.00000  0.000000  0.000000  0.000000  0.000000      1  \n",
       "2    0.00000  0.000000  0.042907  0.074272  0.000000      0  \n",
       "3    0.00000  0.000000  0.091443  0.000000  0.000000      1  \n",
       "4    0.00000  0.101739  0.035454  0.000000  0.057036      0  \n",
       "..       ...       ...       ...       ...       ...    ...  \n",
       "175  0.00000  0.000000  0.000000  0.000000  0.000000      1  \n",
       "176  0.06678  0.000000  0.033112  0.000000  0.053269      0  \n",
       "177  0.00000  0.000000  0.000000  0.000000  0.000000      1  \n",
       "178  0.00000  0.000000  0.000000  0.120872  0.056168      0  \n",
       "179  0.00000  0.000000  0.000000  0.000000  0.049258      0  \n",
       "\n",
       "[180 rows x 878 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign & normalize words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign ranks based on TF-IDF scores \n",
    "def assign_flipped_ranks(row):\n",
    "    ranks = row.rank(method='min', ascending=False)  # Assign ranks (higher score gets lower rank)\n",
    "    max_rank = ranks.max() \n",
    "    if max_rank > 0:\n",
    "        ranks = (max_rank + 1 - ranks) / max_rank #normalize rank to 0-1 scale -> closer to 1 is better rank\n",
    "    ranks[row == 0] = 0  # Assign rank 0 to words not present in the document\n",
    "    return ranks\n",
    "\n",
    "# Apply rank assignment\n",
    "tfidf_ranks_df = tfidf_df.drop(columns=['Genre']).apply(assign_flipped_ranks, axis=1)\n",
    "tfidf_ranks_df['Genre'] = tfidf_df['Genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate words rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate DataFrame by genre\n",
    "sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 1].drop(columns=['Genre'])\n",
    "non_sf_ranks = tfidf_ranks_df[tfidf_ranks_df['Genre'] == 0].drop(columns=['Genre'])\n",
    "\n",
    "# Calculate sum rank for each word in each genre\n",
    "sf_agg_ranks = sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "non_sf_agg_ranks = non_sf_ranks.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "# DataFrame for aggregated ranks\n",
    "sf_agg_ranks_df = pd.DataFrame({'Word': sf_agg_ranks.index, 'SF Total Rank': sf_agg_ranks.values})\n",
    "non_sf_agg_ranks_df = pd.DataFrame({'Word': non_sf_agg_ranks.index, 'Non-SF Total Rank': non_sf_agg_ranks.values})\n",
    "\n",
    "agg_ranks_df = pd.merge(sf_agg_ranks_df, non_sf_agg_ranks_df, on='Word', how='outer')\n",
    "agg_ranks_df['Difference'] = agg_ranks_df['SF Total Rank'] - agg_ranks_df['Non-SF Total Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann–Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "p_values = []\n",
    "\n",
    "# Perform the Mann–Whitney U Test for each word\n",
    "for word in agg_ranks_df['Word']:\n",
    "    # Extract the rank values for the word from the SF and Non-SF DataFrames\n",
    "    sf_ranks_word = sf_ranks[word].values\n",
    "    non_sf_ranks_word = non_sf_ranks[word].values\n",
    "\n",
    "    # Perform the Mann–Whitney U Test\n",
    "    stat, p_value = mannwhitneyu(sf_ranks_word, non_sf_ranks_word, alternative='two-sided')\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Append result\n",
    "agg_ranks_df['P-Value'] = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>SF Total Rank</th>\n",
       "      <th>Non-SF Total Rank</th>\n",
       "      <th>Difference</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>29.596785</td>\n",
       "      <td>2.244200</td>\n",
       "      <td>27.352585</td>\n",
       "      <td>3.612127e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>25.883688</td>\n",
       "      <td>3.881947</td>\n",
       "      <td>22.001742</td>\n",
       "      <td>1.105147e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want</td>\n",
       "      <td>24.942569</td>\n",
       "      <td>6.531943</td>\n",
       "      <td>18.410627</td>\n",
       "      <td>1.395350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>companies</td>\n",
       "      <td>18.418359</td>\n",
       "      <td>1.011325</td>\n",
       "      <td>17.407035</td>\n",
       "      <td>3.929268e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>18.883007</td>\n",
       "      <td>2.383675</td>\n",
       "      <td>16.499332</td>\n",
       "      <td>6.617022e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>driving</td>\n",
       "      <td>6.426507</td>\n",
       "      <td>1.257387</td>\n",
       "      <td>5.169120</td>\n",
       "      <td>2.720250e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>cases</td>\n",
       "      <td>6.809036</td>\n",
       "      <td>1.643788</td>\n",
       "      <td>5.165248</td>\n",
       "      <td>3.021557e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>reach</td>\n",
       "      <td>7.000274</td>\n",
       "      <td>1.910331</td>\n",
       "      <td>5.089943</td>\n",
       "      <td>2.075244e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>example</td>\n",
       "      <td>8.428997</td>\n",
       "      <td>3.370034</td>\n",
       "      <td>5.058963</td>\n",
       "      <td>3.262913e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>understood</td>\n",
       "      <td>6.442389</td>\n",
       "      <td>1.405556</td>\n",
       "      <td>5.036833</td>\n",
       "      <td>2.969431e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  SF Total Rank  Non-SF Total Rank  Difference       P-Value\n",
       "0      business      29.596785           2.244200   27.352585  3.612127e-11\n",
       "1          book      25.883688           3.881947   22.001742  1.105147e-09\n",
       "2          want      24.942569           6.531943   18.410627  1.395350e-03\n",
       "3     companies      18.418359           1.011325   17.407035  3.929268e-09\n",
       "4       company      18.883007           2.383675   16.499332  6.617022e-08\n",
       "..          ...            ...                ...         ...           ...\n",
       "166     driving       6.426507           1.257387    5.169120  2.720250e-02\n",
       "167       cases       6.809036           1.643788    5.165248  3.021557e-02\n",
       "168       reach       7.000274           1.910331    5.089943  2.075244e-02\n",
       "169     example       8.428997           3.370034    5.058963  3.262913e-03\n",
       "170  understood       6.442389           1.405556    5.036833  2.969431e-02\n",
       "\n",
       "[171 rows x 5 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list = agg_ranks_df[(agg_ranks_df['Difference'] > 5) & (agg_ranks_df['P-Value'] < 0.05)].sort_values(by='Difference', ascending=False).reset_index(drop=True)\n",
    "filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.116505802783105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list['Difference'].mean() #can do > 10 or 12 but list too short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping documents with all-zero vectorization (no matching terms in top list): [ 65 149]\n",
      "Training set size: 124\n",
      "Test set size: 54\n",
      "Class distribution in training set: label\n",
      "1    0.508065\n",
      "0    0.491935\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in test set: label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_terms = filter_list['Word'].head(100).values\n",
    "\n",
    "# Vectorize the original corpus\n",
    "vectorizer = TfidfVectorizer(vocabulary=top_terms)  # Restrict vectorization to top terms\n",
    "selected_features = vectorizer.fit_transform(corpus_df['document'])  # Apply vectorizer to original documents\n",
    "\n",
    "\n",
    "# Call out documents with all zero\n",
    "zero_vector_docs = np.where(selected_features.toarray().sum(axis=1) == 0)[0]  # Find indices of documents with all-zero vectors\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Dropping documents with all-zero vectorization (no matching terms in top list): {zero_vector_docs}\")\n",
    "    select_corpus_df = corpus_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    selected_features = vectorizer.fit_transform(select_corpus_df['document'])  # Re-vectorize without dropped docs\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame with selected features (top terms)\n",
    "selected_df = pd.DataFrame(selected_features.toarray(), columns=top_terms)\n",
    "\n",
    "# Add genre labels \n",
    "selected_df['label'] = select_corpus_df['label']\n",
    "\n",
    "# Prepare X and y for training\n",
    "X = selected_df.drop(columns='label')\n",
    "y = selected_df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=45)\n",
    "\n",
    "# Check the balanced split\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "print(\"Class distribution in training set:\", y_train.value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       1.00      0.89      0.94        27\n",
      "Science Fiction & Fantasy       0.90      1.00      0.95        27\n",
      "\n",
      "                 accuracy                           0.94        54\n",
      "                macro avg       0.95      0.94      0.94        54\n",
      "             weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5063867586882749\n",
      "Adjusted Threshold Test Set Performance:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Non-Science Fiction       1.00      0.89      0.94        27\n",
      "Science Fiction & Fantasy       0.90      1.00      0.95        27\n",
      "\n",
      "                 accuracy                           0.94        54\n",
      "                macro avg       0.95      0.94      0.94        54\n",
      "             weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model using the training set\n",
    "final_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_probs = final_model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "# Calculate precision-recall pairs for different thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Choose optimized threshold \n",
    "best_threshold_index = np.argmax(2 * (precisions * recalls) / (precisions + recalls))\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "\n",
    "# Make predictions using the new threshold\n",
    "y_pred_adj = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate performance using the adjusted threshold\n",
    "print(\"Adjusted Threshold Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_adj, target_names=[\"Non-Science Fiction\", \"Science Fiction & Fantasy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Predictive Terms for Science Fiction & Fantasy:\n",
      "          Term  Coefficient\n",
      "0   leadership     1.310379\n",
      "1     business     1.283987\n",
      "2        sales     0.982422\n",
      "3    companies     0.876136\n",
      "4   management     0.810843\n",
      "5      leaders     0.800416\n",
      "6      product     0.751723\n",
      "7     creative     0.701459\n",
      "8        learn     0.694222\n",
      "9        topic     0.674340\n",
      "10   marketing     0.653128\n",
      "11     chapter     0.648998\n",
      "12      number     0.648658\n",
      "13     success     0.645157\n",
      "14     purpose     0.598042\n",
      "15     section     0.582516\n",
      "16    customer     0.563541\n",
      "17    examples     0.540824\n",
      "18    industry     0.538454\n",
      "19       value     0.525903\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Term': X.columns,\n",
    "    'Coefficient': logreg.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top Predictive Terms for Science Fiction & Fantasy:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reserved test set\n",
    "reserved_df = pd.read_csv('../data/corpus/reserved_test_pred.csv')\n",
    "\n",
    "original_reserved_df = reserved_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents with all-zero vectorization found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the reserved test set\n",
    "reserved_features = vectorizer.transform(reserved_df['document'])  # Apply trained vectorizer\n",
    "\n",
    "# Cull out documents with all-zero vectorization\n",
    "zero_vector_docs = np.where(reserved_features.toarray().sum(axis=1) == 0)[0]  \n",
    "\n",
    "# Store ASINs of removed documents \n",
    "removed_asins = reserved_df.iloc[zero_vector_docs]['asin'].tolist()\n",
    "\n",
    "# Drop documents with all-zero vectorization\n",
    "if len(zero_vector_docs) > 0:\n",
    "    print(f\"Removing {len(zero_vector_docs)} documents with all-zero vectorization.\")\n",
    "    reserved_df = reserved_df.drop(index=zero_vector_docs).reset_index(drop=True)  # Drop and reset index\n",
    "    reserved_features = vectorizer.transform(reserved_df['document'])  # Re-vectorize remaining documents\n",
    "else:\n",
    "    print(\"No documents with all-zero vectorization found.\")\n",
    "\n",
    "#Predict probabilities using the final logistic regression model\n",
    "reserved_probs = final_model.predict_proba(reserved_features)[:, 1]  # Probability for class 1 (main genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the reserved_df\n",
    "main_genre = \"Business\" \n",
    "reserved_df[f\"{main_genre}_Prob\"] = reserved_probs.round(2)\n",
    "\n",
    "# Reinsert removed documents with placeholder values\n",
    "original_reserved_df[f\"{main_genre}_Prob\"] = None  # Initialize the probability column with None\n",
    "original_reserved_df.loc[\n",
    "    original_reserved_df['asin'].isin(reserved_df['asin']), \n",
    "    f\"{main_genre}_Prob\"\n",
    "] = reserved_df[f\"{main_genre}_Prob\"].values\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "original_reserved_df.to_csv('../data/corpus/reserved_test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
